{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hackrush.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LWOEH6qDUm_p"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "dataset = pd.read_csv('train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Timestep'] = dataset.Timestep.str[2:6]\n",
        "dataset['Timestep'].astype(int)\n"
      ],
      "metadata": {
        "id": "TX_SySU7NLll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f3baf3-0e04-48db-84f2-2d75202cdf99"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1810\n",
              "1        1810\n",
              "2        1810\n",
              "3        1810\n",
              "4        1810\n",
              "         ... \n",
              "89995    1986\n",
              "89996    1986\n",
              "89997    1986\n",
              "89998    1986\n",
              "89999    1986\n",
              "Name: Timestep, Length: 90000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data = pd.get_dummies(dataset, columns = ['Course', 'Faculty'])\n",
        "dataset = one_hot_encoded_data\n",
        "dataset.insert(0, 'Expected', dataset.pop('Expected'))\n",
        "X = dataset.iloc[:,1:6]\n",
        "Y = dataset.iloc[:,0]"
      ],
      "metadata": {
        "id": "qhNLvjVJOkHp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "tzKFHMi-Infw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing standardscalar module \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "  \n",
        "scalar = StandardScaler()\n",
        "  \n",
        "# fitting\n",
        "scalar.fit(X_train)\n",
        "scaled_data = scalar.transform(X_train)\n",
        "  \n",
        "# Importing PCA\n",
        "from sklearn.decomposition import PCA\n",
        "  \n",
        "# Let's say, components = 2\n",
        "pca = PCA(n_components = 5)\n",
        "pca.fit(X_train)\n",
        "x_pca = pca.transform(X_train)\n",
        "  \n",
        "x_pca.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dna4cQKFk4b",
        "outputId": "c3902a15-ce11-49f7-a5cd-fa54f5ebb565"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing standardscalar module \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "  \n",
        "scalar = StandardScaler()\n",
        "  \n",
        "# fitting\n",
        "scalar.fit(X_test)\n",
        "scaled_data = scalar.transform(X_test)\n",
        "  \n",
        "# Importing PCA\n",
        "from sklearn.decomposition import PCA\n",
        "  \n",
        "# Let's say, components = 2\n",
        "pca = PCA(n_components = 5)\n",
        "pca.fit(X_test)\n",
        "xt_pca = pca.transform(X_test)\n",
        "  \n",
        "xt_pca.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxgUNzRLFhZ6",
        "outputId": "2ea480cf-45ce-49c1-d9f2-4a5500f6be7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "xpscpAp3Rc-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = regr.predict(X_test)"
      ],
      "metadata": {
        "id": "p-G4VmaN0bSI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "5vRKLrksRgBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "i1ioNEb6RnMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c289b1-a96b-445d-b4c1-ebbef206a93a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Regressor"
      ],
      "metadata": {
        "id": "wKe1PCo3mIRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pd.Series(neigh.predict(X_test), index = X_test.index)"
      ],
      "metadata": {
        "id": "JRnXDhSOQgkq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "X_train, Y_train = make_regression(n_features=5, n_informative=2,random_state=0, shuffle=False)\n",
        "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "regr.fit(X_train, Y_train)\n",
        "y_pred = regr.predict(X_test)"
      ],
      "metadata": {
        "id": "Kk3lJ_AkYFpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282be3f1-333b-4384-a2d1-23c39e003b39"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD(best model)"
      ],
      "metadata": {
        "id": "6fYfeM65mOUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "n_samples, n_features = 90000, 5\n",
        "#rng = np.random.RandomState(0)\n",
        "#Y_train = rng.randn(n_samples)\n",
        "#X_train = rng.randn(n_samples, n_features)\n",
        "# Always scale the input. The most convenient way is to use a pipeline.\n",
        "reg = make_pipeline(StandardScaler(),SGDRegressor(loss='squared_error', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False))\n",
        "reg.fit(X_train, Y_train)\n",
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "UU0VSgzuZZ49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562c3d70-d8c1-4ff8-f8a1-df0d22c547c5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:444: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
            "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "he2UbUEsmNX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ABove is the best trained model\n"
      ],
      "metadata": {
        "id": "6Lasyk1ojOnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(Y_test, y_pred, squared=False)"
      ],
      "metadata": {
        "id": "u_h5DgE5UIhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac1cd1f-ee9b-4c75-97b3-c13fda4d2eec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2549096.6656355713"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "adhZ7KxDXrt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Timestep'] = df.Timestep.str[2:6]\n",
        "df['Timestep'].astype(int)"
      ],
      "metadata": {
        "id": "KvsiIMqtYEP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoded_data = pd.get_dummies(df, columns = ['Course', 'Faculty'])\n",
        "df = one_hot_encoded_data\n",
        "df"
      ],
      "metadata": {
        "id": "QBVQg59PqILo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_f = df.iloc[:,0:1219]\n",
        "# Importing standardscalar module \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "  \n",
        "scalar = StandardScaler()\n",
        "  \n",
        "# fitting\n",
        "scalar.fit(X_f)\n",
        "scaled_data = scalar.transform(X_f)\n",
        "  \n",
        "# Importing PCA\n",
        "from sklearn.decomposition import PCA\n",
        "  \n",
        "# Let's say, components = 2\n",
        "pca = PCA(n_components = 5)\n",
        "pca.fit(X_f)\n",
        "x_pca = pca.transform(X_f)\n",
        "  \n",
        "x_pca.shape\n",
        "y_pred_f = pd.Series(regr.predict(x_pca))\n",
        "y_pred_f"
      ],
      "metadata": {
        "id": "4w97C_zJqKta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(data = y_pred_f.index, columns = ['Id'])\n",
        "df2 = pd.DataFrame(data = y_pred_f.values, columns = ['Predicted'])\n",
        "df3 = pd.merge(df1, df2, left_index = True, right_index = True)\n",
        "df3.to_csv('submission.csv', index = False)"
      ],
      "metadata": {
        "id": "i_uQko5mfQt5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}